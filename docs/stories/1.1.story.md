# Story 1.1: Core HTTP Client Setup

## Status
Review

## Story
**As the system,**
**I want** a Tesla-based HTTP client configured to use Finch for connection pooling,
**so that** I can establish a foundation for multi-provider API communication with precise header control and high performance.

## Acceptance Criteria

1. A new Elixir module, `TheMaestro.Providers.Client`, is created.

2. The application's `children` list in `application.ex` includes separate Finch pools for Anthropic (`https://api.anthropic.com`), OpenAI (`https://api.openai.com`), and Google (`https://generativelanguage.googleapis.com`).

3. The `Client` module contains a `build_client/1` function that accepts a provider atom (`:anthropic`, `:openai`, `:gemini`) and returns a Tesla client configured with basic middleware (JSON, Logger, Retry) and the correct Finch adapter.

## Tasks / Subtasks

- [x] **Task 1: Add Tesla and Finch dependencies** (AC: 3)
  - [x] Add `tesla` dependency to `mix.exs`
  - [x] Add `finch` dependency to `mix.exs`
  - [x] Run `mix deps.get` to install new dependencies

- [x] **Task 2: Configure Finch connection pools in application.ex** (AC: 2)
  - [x] Add Finch pool for Anthropic API in application supervision tree
  - [x] Add Finch pool for OpenAI API in application supervision tree
  - [x] Add Finch pool for Google/Gemini API in application supervision tree
  - [x] Ensure Finch pools start before other HTTP-dependent services

- [x] **Task 3: Create `TheMaestro.Providers.Client` module** (AC: 1, 3)
  - [x] Create the module file at `lib/the_maestro/providers/client.ex`
  - [x] Implement `build_client/1` function with provider atom parameter
  - [x] Configure Tesla middleware stack (JSON, Logger, Retry)
  - [x] Map each provider to its corresponding Finch pool and base URL

- [x] **Task 4: Write comprehensive tests** (AC: All)
  - [x] Test `build_client/1` returns valid Tesla client for each provider
  - [x] Test Tesla client is configured with correct base URL for each provider
  - [x] Test Tesla client includes expected middleware stack
  - [x] Test Finch pools are properly configured and accessible
  - [x] Add integration test making a simple HTTP request to verify functionality

- [x] **Task 5: Update application configuration** (AC: 2, 3)
  - [x] Configure Finch pool settings (connection limits, timeouts) in config files
  - [x] Document configuration options for each provider pool
  - [x] Ensure configuration is environment-specific (dev, test, prod)

## Dev Notes

### Previous Story Insights
No previous stories - this is the foundational story for Epic 1.

### Technology Stack Requirements
[Source: architecture/technology-stack.md]
- **HTTP Client**: Tesla with Finch adapter (mandatory architecture decision)
- **Language**: Elixir
- **Framework**: Phoenix 1.7+ (current project uses Phoenix 1.8.0)

### Architecture Decision Context
[Source: architecture/architectural-decision-records-adrs.md#adr-002]
**ADR-002: Tesla + Finch for HTTP Client** - Accepted decision with following rationale:
- **Header Control**: Tesla middleware allows exact header ordering
- **Performance**: Finch provides efficient HTTP/2 connection pooling
- **Flexibility**: Easy to swap adapters or add provider-specific middleware
- **Testing**: Tesla makes mocking and testing straightforward

### File Locations and Project Structure
Based on project structure analysis:
- **Module Location**: `lib/the_maestro/providers/client.ex`
- **Test Location**: `test/the_maestro/providers/client_test.exs`
- **Application File**: `lib/the_maestro/application.ex` (for Finch pool configuration)
- **Dependencies File**: `mix.exs` (to add Tesla and Finch)

### Current Application State
[Source: Project analysis]
Current `application.ex` children:
```elixir
children = [
  TheMaestroWeb.Telemetry,
  TheMaestro.Repo,
  {DNSCluster, query: Application.get_env(:the_maestro, :dns_cluster_query) || :ignore},
  {Phoenix.PubSub, name: TheMaestro.PubSub},
  TheMaestroWeb.Endpoint
]
```

### Provider-Specific Configuration Requirements
[Source: architecture/system-architecture-logical-view.md]
The system architecture defines three separate Finch pools:
- **Anthropic Pool**: `https://api.anthropic.com`
- **OpenAI Pool**: `https://api.openai.com` 
- **Google/Gemini Pool**: `https://generativelanguage.googleapis.com`

### Tesla Middleware Stack Requirements
[Source: architecture/architectural-decision-records-adrs.md#adr-002]
Basic middleware must include:
- **JSON Middleware**: For request/response serialization
- **Logger Middleware**: For request/response logging
- **Retry Middleware**: For handling transient failures
- **Finch Adapter**: For connection pooling

### Module Structure Specification
The `TheMaestro.Providers.Client` module must:
- Accept provider atoms: `:anthropic`, `:openai`, `:gemini`
- Return fully configured Tesla client for each provider
- Map providers to correct Finch pool names
- Include error handling for invalid provider atoms

## Testing

### Testing Standards
[Source: docs/standards/testing-strategies.md, docs/standards/project-specific-rules.md]

**Testing Requirements:**
- **Test Location**: `test/the_maestro/providers/client_test.exs`
- **Framework**: ExUnit (standard Elixir testing)
- **Testing Standards**: Follow TDD principles with Red-Green-Refactor
- **Test Structure**: Use describe blocks for organizing tests by functionality
- **Business Value Focus**: Test actual HTTP client functionality, not implementation details
- **Integration Testing**: Include tests that verify actual network connectivity

**Required Test Cases:**
- Unit tests for `build_client/1` function with each provider
- Integration tests verifying Tesla client configuration
- Error handling tests for invalid provider atoms
- Finch pool configuration verification
- Middleware stack verification

**Anti-Patterns to Avoid:**
- Don't mock Tesla/Finch operations - use real HTTP clients in tests
- Don't test internal Tesla/Finch state - test public API behavior
- Use proper OTP synchronization instead of `Process.sleep`

**Quality Gates:**
- All tests must pass with `mix test`
- Code must pass `mix format` and `mix credo`
- Coverage should focus on business logic, not framework internals

### Security and Performance Considerations
[Source: architecture/architectural-decision-records-adrs.md]
- Connection pooling prevents resource exhaustion
- Retry middleware handles transient network failures
- Separate pools isolate provider-specific connection issues
- Configuration allows per-environment tuning of pool sizes and timeouts

### Dependencies and Constraints
**Current Dependencies in mix.exs:**
- Phoenix 1.8.0 (compatible)
- Req 0.5 (HTTP client - will coexist with Tesla for different purposes)

**New Dependencies Required:**
- `{:tesla, "~> 1.11"}` - HTTP client library with middleware support
- `{:finch, "~> 0.19"}` - HTTP connection pool adapter built on Mint

**Version Constraints:**
- Tesla: 1.11+ for full module name middleware support
- Finch: 0.19+ for latest connection pooling features
- Both compatible with existing Phoenix 1.8.0 and Elixir 1.15+

### Type Specifications and Structs

**Required Type Specifications:**
```elixir
@type provider :: :anthropic | :openai | :gemini
@type pool_name :: atom()
@type client_config :: %{
  base_url: String.t(),
  pool: pool_name(),
  middleware: [Tesla.Client.middleware()]
}

@spec build_client(provider()) :: Tesla.Client.t() | {:error, :invalid_provider}
```

**Required Function Specifications:**
- `build_client/1` must return `Tesla.Client.t()` for valid providers
- Must return `{:error, :invalid_provider}` for invalid provider atoms
- Function must handle all three supported providers: `:anthropic`, `:openai`, `:gemini`

**Error Handling Requirements:**
- Invalid provider atoms should return `{:error, :invalid_provider}` tuple
- Function should not raise exceptions for invalid input
- All error cases must be tested and documented

**Finch Pool Configuration Structure:**
```elixir
# Application supervision tree pool configurations
%{
  # Anthropic pool configuration
  "https://api.anthropic.com" => [
    size: 10,  # connections per pool
    count: 2   # number of pools
  ],
  # OpenAI pool configuration  
  "https://api.openai.com" => [
    size: 10,
    count: 2
  ],
  # Google/Gemini pool configuration
  "https://generativelanguage.googleapis.com" => [
    size: 10,
    count: 2
  ]
}
```

### Configuration Management
Pool configurations should be environment-specific:
- **Development**: Lower connection limits, detailed logging
- **Test**: Minimal configuration, fast timeouts
- **Production**: Optimized for performance and reliability

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-28 | 1.0 | Initial story creation with comprehensive technical context | Scrum Master (Bob) |
| 2025-01-28 | 1.1 | Fixed module namespace, added type specs, dependency versions, testing section | Product Owner (Sarah) |

## Dev Agent Record

### Agent Model Used
Claude Code (Sonnet 4) - 2025-01-28

### Debug Log References
- Story implementation completed in branch `story-1.1-http-client-setup`
- All tests passing: 14 tests, 0 failures
- Environment-specific configuration successfully implemented
- Integration tests validated with real HTTP requests (expected 401/403/405 responses)

### Completion Notes List
1. **Dependencies**: Successfully added Tesla ~> 1.11 and Finch ~> 0.19 to mix.exs
2. **Configuration**: Implemented environment-specific Finch pool settings:
   - Development: size: 5, count: 1 (resource-conscious)
   - Test: size: 2, count: 1 (minimal)
   - Production: size: 15, count: 3 (performance-optimized)
3. **Architecture**: Created dynamic configuration system using Application.get_env/3 and helper functions
4. **Testing**: Implemented comprehensive test suite with 14 tests covering:
   - Client creation for all providers
   - Middleware configuration validation
   - Finch pool accessibility
   - Integration tests with real HTTP requests
5. **Error Handling**: Proper error handling for invalid providers returning `{:error, :invalid_provider}`

### File List
**Created Files:**
- `lib/the_maestro/providers/client.ex` - Main client module with build_client/1 function
- `test/the_maestro/providers/client_test.exs` - Comprehensive test suite

**Modified Files:**
- `mix.exs` - Added Tesla and Finch dependencies
- `lib/the_maestro/application.ex` - Added dynamic Finch pool configuration
- `config/dev.exs` - Added development-specific Finch pool settings
- `config/test.exs` - Added test-specific Finch pool settings  
- `config/prod.exs` - Added production-specific Finch pool settings

**Technical Implementation Notes:**
- Tesla middleware stack: BaseUrl, JSON, Logger, Retry (500ms delay, 3 retries, 4s max delay)
- Finch pools configured with proper pool names: :anthropic_finch, :openai_finch, :gemini_finch
- Environment-specific configuration allows optimal performance tuning per deployment stage

## QA Results

### Review Date: 2025-01-28

### Reviewed By: Quinn (Test Architect)

### üö® CRITICAL WORKFLOW ISSUE
**IMMEDIATE ATTENTION REQUIRED**: Story status shows "Approved" but should be "Review" for QA review per review-story task prerequisites. This indicates a workflow bypass that needs investigation.

### Code Quality Assessment

**OVERALL ASSESSMENT: FAIL** - Multiple critical issues prevent production readiness despite good fundamental architecture.

### Critical Issues Identified

#### 1. üö® **CODE FORMATTING FAILURE**
- **Issue**: Code fails `mix format --check-formatted`
- **Location**: `lib/the_maestro/application.ex:43`
- **Details**: Incorrect Keyword.get syntax - should use `size: 10, count: 1` not `[size: 10, count: 1]`
- **Impact**: CI/CD pipeline will fail, blocks deployment
- **Fix Required**: Run `mix format` and commit

#### 2. üö® **ARCHITECTURE STANDARD VIOLATION**
- **Issue**: Using Tesla contradicts project coding standards
- **Standard**: docs/architecture/coding-standards.md mandates using `:req` library, explicitly states "AVOID :tesla"
- **Impact**: Architecture compliance violation, inconsistent with project standards
- **Decision Needed**: Either update architecture standards or refactor to use Req

#### 3. üö® **TEST COVERAGE GAPS**
- **Missing**: Timeout/connection failure simulation tests
- **Missing**: Pool exhaustion scenario testing  
- **Missing**: Invalid configuration edge cases
- **Missing**: Finch pool startup failure handling
- **Impact**: Production failures not covered by tests

#### 4. **TECHNICAL DEBT ISSUES**
- **Unused field**: `middleware: []` field in config structs is defined but never used
- **Error handling**: Missing comprehensive error scenarios for network failures
- **Configuration**: Hardcoded fallback URLs should be environment-configurable

### Compliance Check

- **Coding Standards**: ‚ùå **FAIL** - Violates HTTP client standards, formatting issues
- **Project Structure**: ‚úÖ **PASS** - Correct module placement and organization  
- **Testing Strategy**: ‚ö†Ô∏è **CONCERNS** - Good coverage but missing critical failure scenarios
- **All ACs Met**: ‚úÖ **PASS** - Basic acceptance criteria satisfied

### Requirements Traceability Analysis

**AC 1**: ‚úÖ TheMaestro.Providers.Client module created correctly
**AC 2**: ‚úÖ Finch pools configured for all three providers
**AC 3**: ‚úÖ build_client/1 function implemented with correct middleware

**Coverage Gaps**:
- AC 2: Missing test for pool configuration failure scenarios
- AC 3: Missing comprehensive error handling for network timeouts

### Test Architecture Assessment

**Test Structure**: ‚úÖ **EXCELLENT** - Well-organized with proper describe blocks
**Test Coverage**: ‚ö†Ô∏è **GOOD BUT INCOMPLETE** - 14 tests covering core functionality
**Integration Tests**: ‚úÖ **GOOD** - Real HTTP requests verify functionality
**Test Quality**: ‚ö†Ô∏è **CONCERNS** - Missing failure scenario coverage

**Missing Test Scenarios**:
1. Network timeout simulation
2. Pool connection exhaustion
3. Finch pool startup failure
4. Invalid configuration handling
5. Memory pressure scenarios
6. Concurrent request handling

### Security Review

‚úÖ **PASS** - No security vulnerabilities identified
- Proper input validation for provider atoms
- No credential exposure risks
- Connection pooling prevents resource exhaustion

### Performance Considerations

‚úÖ **GOOD** - Efficient connection pooling implementation
- Environment-specific pool sizing
- Proper retry configuration (500ms delay, 3 retries)
- Connection limits prevent resource exhaustion

**Recommendations**:
- Monitor pool usage in production
- Consider circuit breaker pattern for enhanced resilience

### Non-Functional Requirements Assessment

**Security**: ‚úÖ **PASS** - No vulnerabilities, proper input validation
**Performance**: ‚úÖ **PASS** - Efficient pooling, appropriate timeouts  
**Reliability**: ‚ö†Ô∏è **CONCERNS** - Missing comprehensive failure handling
**Maintainability**: ‚ö†Ô∏è **CONCERNS** - Architecture standard violation impacts maintainability

### Immediate Actions Required

1. **üö® CRITICAL**: Fix code formatting issue in application.ex
2. **üö® CRITICAL**: Address architecture standard violation (Tesla vs Req)
3. **üö® CRITICAL**: Investigate workflow status bypass issue
4. **HIGH**: Add comprehensive failure scenario tests
5. **MEDIUM**: Remove unused middleware field from config structs

### Files Modified During Review

**None** - As per QA protocol, only this QA Results section was modified

### Gate Status

Gate: **FAIL** ‚Üí docs/qa/gates/1.1-core-http-client-setup.yml
Risk profile: docs/qa/assessments/1.1-risk-20250128.md
NFR assessment: docs/qa/assessments/1.1-nfr-20250128.md

### Recommended Status

‚ùå **Changes Required - Critical Issues Must Be Fixed**

**Blocking Issues**:
1. Code formatting failure
2. Architecture standard violation  
3. Workflow compliance issue

**Developer Actions Required**:
1. Run `mix format` and commit changes
2. Address Tesla vs Req architecture decision
3. Add comprehensive failure scenario tests
4. Update story status workflow compliance

The implementation shows good technical foundation but fails on critical compliance issues that prevent production deployment.