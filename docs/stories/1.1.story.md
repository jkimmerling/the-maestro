# Story 1.1: Core HTTP Client Setup

## Status
Approved

## Story
**As the system,**
**I want** a Tesla-based HTTP client configured to use Finch for connection pooling,
**so that** I can establish a foundation for multi-provider API communication with precise header control and high performance.

## Acceptance Criteria

1. A new Elixir module, `TheMaestro.Providers.Client`, is created.

2. The application's `children` list in `application.ex` includes separate Finch pools for Anthropic (`https://api.anthropic.com`), OpenAI (`https://api.openai.com`), and Google (`https://generativelanguage.googleapis.com`).

3. The `Client` module contains a `build_client/1` function that accepts a provider atom (`:anthropic`, `:openai`, `:gemini`) and returns a Tesla client configured with basic middleware (JSON, Logger, Retry) and the correct Finch adapter.

## Tasks / Subtasks

- [x] **Task 1: Add Tesla and Finch dependencies** (AC: 3)
  - [x] Add `tesla` dependency to `mix.exs`
  - [x] Add `finch` dependency to `mix.exs`
  - [x] Run `mix deps.get` to install new dependencies

- [x] **Task 2: Configure Finch connection pools in application.ex** (AC: 2)
  - [x] Add Finch pool for Anthropic API in application supervision tree
  - [x] Add Finch pool for OpenAI API in application supervision tree
  - [x] Add Finch pool for Google/Gemini API in application supervision tree
  - [x] Ensure Finch pools start before other HTTP-dependent services

- [x] **Task 3: Create `TheMaestro.Providers.Client` module** (AC: 1, 3)
  - [x] Create the module file at `lib/the_maestro/providers/client.ex`
  - [x] Implement `build_client/1` function with provider atom parameter
  - [x] Configure Tesla middleware stack (JSON, Logger, Retry)
  - [x] Map each provider to its corresponding Finch pool and base URL

- [x] **Task 4: Write comprehensive tests** (AC: All)
  - [x] Test `build_client/1` returns valid Tesla client for each provider
  - [x] Test Tesla client is configured with correct base URL for each provider
  - [x] Test Tesla client includes expected middleware stack
  - [x] Test Finch pools are properly configured and accessible
  - [x] Add integration test making a simple HTTP request to verify functionality

- [x] **Task 5: Update application configuration** (AC: 2, 3)
  - [x] Configure Finch pool settings (connection limits, timeouts) in config files
  - [x] Document configuration options for each provider pool
  - [x] Ensure configuration is environment-specific (dev, test, prod)

## Dev Notes

### Previous Story Insights
No previous stories - this is the foundational story for Epic 1.

### Technology Stack Requirements
[Source: architecture/technology-stack.md]
- **HTTP Client**: Tesla with Finch adapter (mandatory architecture decision)
- **Language**: Elixir
- **Framework**: Phoenix 1.7+ (current project uses Phoenix 1.8.0)

### Architecture Decision Context
[Source: architecture/architectural-decision-records-adrs.md#adr-002]
**ADR-002: Tesla + Finch for HTTP Client** - Accepted decision with following rationale:
- **Header Control**: Tesla middleware allows exact header ordering
- **Performance**: Finch provides efficient HTTP/2 connection pooling
- **Flexibility**: Easy to swap adapters or add provider-specific middleware
- **Testing**: Tesla makes mocking and testing straightforward

### File Locations and Project Structure
Based on project structure analysis:
- **Module Location**: `lib/the_maestro/providers/client.ex`
- **Test Location**: `test/the_maestro/providers/client_test.exs`
- **Application File**: `lib/the_maestro/application.ex` (for Finch pool configuration)
- **Dependencies File**: `mix.exs` (to add Tesla and Finch)

### Current Application State
[Source: Project analysis]
Current `application.ex` children:
```elixir
children = [
  TheMaestroWeb.Telemetry,
  TheMaestro.Repo,
  {DNSCluster, query: Application.get_env(:the_maestro, :dns_cluster_query) || :ignore},
  {Phoenix.PubSub, name: TheMaestro.PubSub},
  TheMaestroWeb.Endpoint
]
```

### Provider-Specific Configuration Requirements
[Source: architecture/system-architecture-logical-view.md]
The system architecture defines three separate Finch pools:
- **Anthropic Pool**: `https://api.anthropic.com`
- **OpenAI Pool**: `https://api.openai.com` 
- **Google/Gemini Pool**: `https://generativelanguage.googleapis.com`

### Tesla Middleware Stack Requirements
[Source: architecture/architectural-decision-records-adrs.md#adr-002]
Basic middleware must include:
- **JSON Middleware**: For request/response serialization
- **Logger Middleware**: For request/response logging
- **Retry Middleware**: For handling transient failures
- **Finch Adapter**: For connection pooling

### Module Structure Specification
The `TheMaestro.Providers.Client` module must:
- Accept provider atoms: `:anthropic`, `:openai`, `:gemini`
- Return fully configured Tesla client for each provider
- Map providers to correct Finch pool names
- Include error handling for invalid provider atoms

## Testing

### Testing Standards
[Source: docs/standards/testing-strategies.md, docs/standards/project-specific-rules.md]

**Testing Requirements:**
- **Test Location**: `test/the_maestro/providers/client_test.exs`
- **Framework**: ExUnit (standard Elixir testing)
- **Testing Standards**: Follow TDD principles with Red-Green-Refactor
- **Test Structure**: Use describe blocks for organizing tests by functionality
- **Business Value Focus**: Test actual HTTP client functionality, not implementation details
- **Integration Testing**: Include tests that verify actual network connectivity

**Required Test Cases:**
- Unit tests for `build_client/1` function with each provider
- Integration tests verifying Tesla client configuration
- Error handling tests for invalid provider atoms
- Finch pool configuration verification
- Middleware stack verification

**Anti-Patterns to Avoid:**
- Don't mock Tesla/Finch operations - use real HTTP clients in tests
- Don't test internal Tesla/Finch state - test public API behavior
- Use proper OTP synchronization instead of `Process.sleep`

**Quality Gates:**
- All tests must pass with `mix test`
- Code must pass `mix format` and `mix credo`
- Coverage should focus on business logic, not framework internals

### Security and Performance Considerations
[Source: architecture/architectural-decision-records-adrs.md]
- Connection pooling prevents resource exhaustion
- Retry middleware handles transient network failures
- Separate pools isolate provider-specific connection issues
- Configuration allows per-environment tuning of pool sizes and timeouts

### Dependencies and Constraints
**Current Dependencies in mix.exs:**
- Phoenix 1.8.0 (compatible)
- Req 0.5 (HTTP client - will coexist with Tesla for different purposes)

**New Dependencies Required:**
- `{:tesla, "~> 1.11"}` - HTTP client library with middleware support
- `{:finch, "~> 0.19"}` - HTTP connection pool adapter built on Mint

**Version Constraints:**
- Tesla: 1.11+ for full module name middleware support
- Finch: 0.19+ for latest connection pooling features
- Both compatible with existing Phoenix 1.8.0 and Elixir 1.15+

### Type Specifications and Structs

**Required Type Specifications:**
```elixir
@type provider :: :anthropic | :openai | :gemini
@type pool_name :: atom()
@type client_config :: %{
  base_url: String.t(),
  pool: pool_name(),
  middleware: [Tesla.Client.middleware()]
}

@spec build_client(provider()) :: Tesla.Client.t() | {:error, :invalid_provider}
```

**Required Function Specifications:**
- `build_client/1` must return `Tesla.Client.t()` for valid providers
- Must return `{:error, :invalid_provider}` for invalid provider atoms
- Function must handle all three supported providers: `:anthropic`, `:openai`, `:gemini`

**Error Handling Requirements:**
- Invalid provider atoms should return `{:error, :invalid_provider}` tuple
- Function should not raise exceptions for invalid input
- All error cases must be tested and documented

**Finch Pool Configuration Structure:**
```elixir
# Application supervision tree pool configurations
%{
  # Anthropic pool configuration
  "https://api.anthropic.com" => [
    size: 10,  # connections per pool
    count: 2   # number of pools
  ],
  # OpenAI pool configuration  
  "https://api.openai.com" => [
    size: 10,
    count: 2
  ],
  # Google/Gemini pool configuration
  "https://generativelanguage.googleapis.com" => [
    size: 10,
    count: 2
  ]
}
```

### Configuration Management
Pool configurations should be environment-specific:
- **Development**: Lower connection limits, detailed logging
- **Test**: Minimal configuration, fast timeouts
- **Production**: Optimized for performance and reliability

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-28 | 1.0 | Initial story creation with comprehensive technical context | Scrum Master (Bob) |
| 2025-01-28 | 1.1 | Fixed module namespace, added type specs, dependency versions, testing section | Product Owner (Sarah) |

## Dev Agent Record

### Agent Model Used
Claude Code (Sonnet 4) - 2025-01-28

### Debug Log References
- Story implementation completed in branch `story-1.1-http-client-setup`
- All tests passing: 14 tests, 0 failures
- Environment-specific configuration successfully implemented
- Integration tests validated with real HTTP requests (expected 401/403/405 responses)

### Completion Notes List
1. **Dependencies**: Successfully added Tesla ~> 1.11 and Finch ~> 0.19 to mix.exs
2. **Configuration**: Implemented environment-specific Finch pool settings:
   - Development: size: 5, count: 1 (resource-conscious)
   - Test: size: 2, count: 1 (minimal)
   - Production: size: 15, count: 3 (performance-optimized)
3. **Architecture**: Created dynamic configuration system using Application.get_env/3 and helper functions
4. **Testing**: Implemented comprehensive test suite with 14 tests covering:
   - Client creation for all providers
   - Middleware configuration validation
   - Finch pool accessibility
   - Integration tests with real HTTP requests
5. **Error Handling**: Proper error handling for invalid providers returning `{:error, :invalid_provider}`

### File List
**Created Files:**
- `lib/the_maestro/providers/client.ex` - Main client module with build_client/1 function
- `test/the_maestro/providers/client_test.exs` - Comprehensive test suite

**Modified Files:**
- `mix.exs` - Added Tesla and Finch dependencies
- `lib/the_maestro/application.ex` - Added dynamic Finch pool configuration
- `config/dev.exs` - Added development-specific Finch pool settings
- `config/test.exs` - Added test-specific Finch pool settings  
- `config/prod.exs` - Added production-specific Finch pool settings

**Technical Implementation Notes:**
- Tesla middleware stack: BaseUrl, JSON, Logger, Retry (500ms delay, 3 retries, 4s max delay)
- Finch pools configured with proper pool names: :anthropic_finch, :openai_finch, :gemini_finch
- Environment-specific configuration allows optimal performance tuning per deployment stage

## QA Results

_Results from QA Agent review of the completed story implementation will be populated here._